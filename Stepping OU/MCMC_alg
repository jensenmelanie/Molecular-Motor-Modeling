 
##================================================
## Algorithm Function
##=================================================

	
BMdrift_MCMC_alg = function(data, iterations = 4000){	
##-------------------------------------------------
## Setting the hyperparameters and initializing 
##-------------------------------------------------
time = data$time; Delta_n = diff(time); num_incr = length(diff(data$Xn))
Xn = data$Xn


lambda_0 = rnorm(1, mean = 1, sd = 1)
 eta_0 = rgamma(1, shape =1, rate = 1)
 
##-------------------------------------------------
## Defining output
##-------------------------------------------------
post_samp = list(lambda = vector(length = iterations), eta = vector(length = iterations))

post_samp$lambda[1] = lambda_0
post_samp$eta[1] = eta_0

for( n in 1:(iterations -1)){

##-------------------------------------------------
## Lambda block
##-------------------------------------------------
lambda_post_mu = sum(diff(Xn)/sum(Delta_n))
lambda_post_sigma = sqrt((post_samp$eta[n]*sum(Delta_n))^(-1))
post_samp$lambda[n+1] = rnorm(n = 1, mean = lambda_post_mu, sd = lambda_post_sigma)


##-------------------------------------------------
## eta block
##-------------------------------------------------
eta_post_alpha = num_incr/2
eta_post_beta = (1/2)*sum((diff(Xn) - post_samp$lambda[n+1]*Delta_n)^2/Delta_n)
post_samp$eta[n+1] = rgamma(n = 1, shape = eta_post_alpha, rate = eta_post_beta)

} #end of the sampling loop

return(list(post_samp = post_samp, inital = c(lambda_0, eta_0)))

} #end of the iterations loop


##=============================================
## Algorithm for Multiple Chains
##=============================================


BMdrift_chains = function(mydata, num_chains = 2,iterations = 10000, warmup_per = 0.5,every_kth = 1, plot_it = FALSE){

sampling_seq = seq(ceiling(iterations*warmup_per)+ every_kth, iterations, by = every_kth)


all_chains = list()
all_post = list()


all_chains[[1]] = BMdrift_MCMC_alg(mydata, iterations)
all_post[[1]] = all_chains[[1]]$post_samp

if(plot_it == TRUE){
lambda_violin = plot_post_violin(matrix(all_chains[[1]]$post_samp$lambda, ncol = 1), parname= c(paste("lambda", 1)), every_kth = every_kth, warmup = warmup_per)
eta_violin = plot_post_violin(matrix(log10(all_chains[[1]]$post_samp$eta), ncol = 1), parname= c(paste("log10eta", 1)), every_kth = every_kth, warmup = warmup_per)
 grid.arrange( lambda_violin, eta_violin, ncol = 2, top = textGrob("Chain 1",gp = gpar(fontsize = 18)))
}


for( m in 2:num_chains){
	all_chains[[m]] = BMdrift_MCMC_alg(mydata, iterations)
	all_post[[m]] = all_chains[[m]]$post_samp
if(plot_it == TRUE){
lambda_violin = plot_post_violin(matrix(all_chains[[m]]$post_samp$lambda, ncol = 1), parname= c(paste("lambda", 1)), every_kth = every_kth, warmup = warmup_per)
eta_violin = plot_post_violin(matrix(log10(all_chains[[m]]$post_samp$eta), ncol = 1), parname= c(paste("log10eta", 1)), every_kth = every_kth, warmup = warmup_per)
 grid.arrange( lambda_violin, eta_violin, ncol = 2, top = textGrob(paste("Chain ",m),gp = gpar(fontsize = 18)))
}

}
names(all_chains) = paste("chain", 1:num_chains, sep = '')
names(all_post) = paste("chain", 1:num_chains, sep = '')
##-------------------------------------------
##Model Comparison Stats
##-------------------------------------------
model_comp_stats = matrix(nrow = 2, ncol = 1)
rownames(model_comp_stats) = c("log10PBS", "ElogL")

post_lambda  = c(sapply(all_post, get_postsamp_1d, parname= 'lambda')[sampling_seq,])
post_eta = c(sapply(all_post, get_postsamp_1d, parname= 'eta')[sampling_seq,])

sub_post = list(lambda = post_lambda, eta = post_eta)
model_comp_stats[,1] = c(log10(PBS_BMdrift(mydata, sub_post, num_switch_pts = 0, every_kth = 1, burn_in_per = 0)),pwaic_BMdrift(mydata, sub_post, num_switch_pts = 0, every_kth = 1, burn_in_per= 0))




##-------------------------------------------
##Convergence statistics (Rhat and neff)
##-------------------------------------------

parnames = names(all_post[[1]])
Rhat_values = matrix(nrow = length(parnames), ncol = 1)
rownames(Rhat_values) = parnames
colnames(Rhat_values) = c('state 1')

neff_values = matrix(nrow = length(parnames), ncol =1)
rownames(neff_values) = parnames
colnames(neff_values) = c('state 1')



pp = 0
for(pn in parnames){
	num_states = 1
	pp = pp + 1

		chain_mat= matrix(unlist(lapply(all_post, get_postsamp_1d, parname = pn)), nrow = iterations, ncol = num_chains)
		chain_mat  = chain_mat[sampling_seq,] 
		
		conv_stats = convergence_stats_fnc(chain_mat)
		
		Rhat_values[pp,1] = conv_stats$Rhat
		neff_values[pp,1] = conv_stats$neff
		
		
		
} # End of the parameter loops
print("Potential Scale Reduction Factor (< 1.1)")
print(Rhat_values)
print("Number of Effective Samples (> 5*2*num_chains)")
print(neff_values)
return(list(chain_output= all_chains,Rhat =  Rhat_values,neff = neff_values, model_comp = model_comp_stats))

} #End of the function




##================================================
## Helper Functions
##=================================================


get_postsamp_1d = function(post_samples,parname){
	return(post_samples[[parname]])
}

 variogram_fnc = function(post_matrix, lag_t){
	num_chains = ncol(post_matrix)
	num_lags =nrow(post_matrix) - lag_t
	return((1/num_chains)*(1/num_lags)*sum(apply(post_matrix, 2,diff, lag = lag_t)^2))	
}


convergence_stats_fnc = function(post_matrix){
	if(is.matrix(post_matrix) == FALSE){
		stop("Posterior Samples need to be in a matrix with (i,j)th entry is the ith sample from the jth chain")
	}
	
## To calculate the variance of the samples	
	num_samples  = nrow(post_matrix)
	
	first_half = 1:floor(num_samples/2); second_half = (floor(num_samples/2)+1):num_samples
	 num_split_samp = length(first_half)
	
	
	first_mat = post_matrix[first_half, ];second_mat = post_matrix[second_half, ]
	
	num_chains  = 2*ncol(post_matrix)

	chain_mean = c(apply(first_mat, 2, mean),apply(second_mat, 2, mean))
	grand_mean = mean(post_matrix)

	Between_var = (num_split_samp/(num_chains-1))*sum((chain_mean - rep(grand_mean, length(chain_mean)))^2)
	
	Within_var = mean(c(apply(first_mat, 2, var),apply(second_mat, 2, var)))
	
	Var_est = ((num_split_samp-1)/num_split_samp)*Within_var + (1/num_split_samp)*Between_var


## Rhat Statistic	
	Rhat = sqrt(Var_est/ Within_var)	
	
## N effective - only makes sense to compute when the chain is well mixed
	
	if(Rhat <=1.1){
	rho_hat_t = 1-(sapply(1:num_split_samp, variogram_fnc, post_matrix = post_matrix)/(2*Var_est))
	
	odds_seq = seq(1, num_split_samp-2, by = 2)	
		
	lag_T = min(odds_seq[which(rho_hat_t[odds_seq + 1] + rho_hat_t[odds_seq + 2] < 0)], num_split_samp)
	
	if(lag_T == num_split_samp){print(paste("T = ", num_split_samp))}
	
	neff = (num_chains*num_split_samp)/(1 + 2*sum(rho_hat_t[1:lag_T]))
	}else{
		neff = NA
		}
	
	
	return(list(Rhat = Rhat, neff = neff))
}
