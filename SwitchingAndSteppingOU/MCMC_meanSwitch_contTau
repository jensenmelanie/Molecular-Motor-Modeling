
library(grid)
library(gridExtra)
library(ggplot2)

##================================================
## Algorithm Function
##=================================================

BMdrift_Meanswitch_contTau = function(mydata, num_switches,init_tau = 'uniform', cand_tau_step_per = 0.05,min_dur = 2,iterations = 4000, warmup_per = 0.5,plot_it = TRUE){

min_delta = min(unique(diff(mydata$time)))
num_obs = length(mydata$time)
num_states = num_switches + 1

if(num_states*(min_dur+1)>= num_obs){
	stop("Not enough observations for each state to be observed for the given number of minimum observations")
}


##---------------------------------------------------------------------
## Storing the posterior samples
##---------------------------------------------------------------------
tau_support = c(mydata$time[min_dur+1],mydata$time[num_obs-min_dur+1])
## we add one because we want 10 increments per state

post_samp = list()
post_samp$lambda = matrix(nrow = iterations, ncol = num_states)
post_samp$eta = matrix(nrow = iterations, ncol = 1)
post_samp$tau = matrix(nrow = iterations, ncol = num_switches)

overlapping_intervals= matrix(nrow = iterations, ncol = num_switches)
accept_rates = matrix(nrow = iterations, ncol = num_switches)

##---------------------------------------------------------------------
## Initializing
##---------------------------------------------------------------------
if(init_tau == 'uniform'){
	initial_tau = diff(tau_support)*((1:num_switches)/num_states)
	post_samp$tau[1,] = initial_tau
}else{
	
	initial_tau = runif(n= 1, min = tau_support[1], max = mydata$time[num_obs -(min_dur+1)*num_switches] )

	if(num_switches >1){
		for(j in 1:(num_switches-1)){
			initial_tau = c(initial_tau, runif(n =1, min = mydata$time[get_tau_index(initial_tau[j], mydata$time) + (min_dur+1)], max = mydata$time[num_obs- (min_dur+1)*(num_switches -j)]))
			}	
	}
	post_samp$tau[1,] = initial_tau
}


initial_lambda = rnorm(n = num_states, mean  =500, sd = 50)
post_samp$lambda[1,] = initial_lambda
initial_eta = rgamma(n = 1, shape = .1, rate = .1)
post_samp$eta[1,] = initial_eta

cand_var_tau = ceiling(length(mydata$Xn)*cand_tau_step_per)*min_delta

if(length(cand_var_tau) == 1){
	cand_var_tau = rep(cand_var_tau, num_switches)	}
else if(length(cand_var_tau)!= num_switches){
	stop("The chosen cand_var_tau needs to be length 1 or number of switch points")
}



##---------------------------------------------------------------------
## Sampling
##---------------------------------------------------------------------

for( it in 2:iterations){

tau_vec_it =c(mydata$time[1], post_samp$tau[it-1,], mydata$time[num_obs])

tau_index = sapply(post_samp$tau[it-1, ], get_tau_index, time_seq = mydata$time)
tau_index_vec_it = c(1,tau_index, num_obs)

state_list = list()
Delta_n_st = list()
Xincr_st = list()


## We are assuming that the switch point occrs at n_tau

for(st in 1:num_states){
	state_list[[st]] = (tau_index_vec_it[st]): tau_index_vec_it[st+1]	
	Delta_n_st[[st]] = diff(mydata$time[state_list[[st]]])
	Xincr_st[[st]] = diff(mydata$Xn[state_list[[st]]])
	}




##-----------------------------eta block-----------------------------
## We are assuming that eta stays the same for each state
eta_post_alpha = num_obs/2 #+ mydata$hyper_eta[1,]
eta_post_beta_st = c()

for(st in 1:num_states){
	eta_post_beta_st = c(eta_post_beta_st,(Xincr_st[[st]] - Delta_n_st[[st]]*post_samp$lambda[it-1,st])^2/(Delta_n_st[[st]]) )
}

eta_post_beta = (1/2)*sum(eta_post_beta_st)

post_samp$eta[it,] = rgamma(n= 1, shape = eta_post_alpha, rate = eta_post_beta)


##-----------------------------lambda block-----------------------------

## Jeffreys prior (ie flat on lambda)

lambda_post_var = (unlist(lapply(Delta_n_st,sum))*post_samp$eta[it,])^(-1)
lambda_post_mean = unlist(lapply(Xincr_st, sum))/unlist(lapply(Delta_n_st,sum))

post_samp$lambda[it,] = unlist(lapply(col_to_list(rbind(lambda_post_mean,lambda_post_var)), rnorm_list, n = 1))

##-----------------------------tau block-----------------------------


for(st in 1:num_switches){
	
	tau_loop_vec = tau_vec_it[st:(st+2)]
	tau_index_loop_vec = tau_index_vec_it[st:(st+2)]

	cand_tau = sampler_uniform(tau_loop_vec[2], cand_var_tau[st])
	cand_tau_vec = tau_loop_vec; cand_tau_vec[2] = cand_tau
	cand_tau_index_vec = sapply(cand_tau_vec, get_tau_index, mydata$time)
	
	overlapping_indicator = as.numeric(cand_tau_index_vec[2]<= (cand_tau_index_vec[1]+min_dur -1) ) + as.numeric(cand_tau_index_vec[2] >=(cand_tau_index_vec[3]-min_dur+1))+ as.numeric(cand_tau <= tau_support[1]) + as.numeric(cand_tau >= tau_support[2])
	
	 #overlapping_indicator = as.numeric(cand_tau<= mydata$time[cand_tau_index_vec[1]+min_dur +1] ) +  as.numeric(cand_tau >= mydata$time[cand_tau_index_vec[3]-min_dur+1]) + as.numeric(cand_tau <= tau_support[1]) + as.numeric(cand_tau >= tau_support[2])
	
	if( overlapping_indicator > 0){
		ratio = 0; overlapping_intervals[it, st] = 1
	}else{
	
		switch_lambdas = post_samp$lambda[it,c(st,st+1)]; 
		switch_etas = rep(post_samp$eta[it,], time= 2)
		

		log_like_ratio = ll_switch_interval(mydata$time, mydata$Xn, cand_tau_index_vec, switch_lambdas, switch_etas) - ll_switch_interval(mydata$time,mydata$Xn, tau_index_loop_vec, switch_lambdas, switch_etas)
				
		ratio = exp(log_like_ratio)	
		
	} #End of get the ratio
	
	
	accept_fnc_tau = min(1, ratio)
	
	
	if(	runif(1,min = 0, max = 1) <= accept_fnc_tau){
		post_samp$tau[it, st] = cand_tau; accept_rates[it,st] = 1
		tau_vec_it[st+1] = cand_tau
	}else {
		post_samp$tau[it, st] = post_samp$tau[it-1,st]; accept_rates[it,st] = 0
	}

	
} # End of the tau loop



} # End of the iterations loop

return(list(post_samp= post_samp, tau_accept = accept_rates, initial_tau = initial_tau))

} #End of the function



##=============================================
## Algorithm for Multiple Chains with Nefff
##=============================================



BMdrift_switchMean_chains = function(mydata, num_switches, num_chains = 2, cand_tau_step_per = 0.05,min_dur = 2, iterations = 10000, warmup_per = 0.5,every_kth = 1,plot_it = FALSE){


if(num_chains == 1){
	stop_message = "Number of chains must be > 1"
	stop(stop_message) 
}



sampling_seq = seq(ceiling(iterations*warmup_per)+ every_kth, iterations, by = every_kth)


all_chains = list()
all_post = list()


all_chains[[1]] = BMdrift_Meanswitch_contTau(mydata, num_switches,init_tau = 'uniform',cand_tau_step_per,min_dur = min_dur,iterations =  iterations,warmup_per =  warmup_per, plot_it = FALSE)



if(plot_it == TRUE){
lambda_violin = plot_post_violin(all_chains[[1]]$post_samp$lambda, parname= c(paste("lambda", 1:(num_switches+1))), every_kth = every_kth)
eta_violin = plot_post_violin(matrix(log10(all_chains[[1]]$post_samp$eta), ncol = 1), parname= c(paste("log10eta", 1)), every_kth = every_kth)
tau_violin = plot_post_violin(all_chains[[1]]$post_samp$tau, parname= c(paste("tau", 1:num_switches)), par_range = range(mydata$time),every_kth = every_kth)
grid.arrange(tau_violin, lambda_violin, eta_violin, layout_matrix = cbind(c(1,1,1),c(2,2,3)), top = textGrob("Chain 1",gp = gpar(fontsize = 18)))
}


all_post[[1]] = list(lambda = all_chains[[1]]$post_samp$lambda[sampling_seq,], eta = matrix(all_chains[[1]]$post_samp$eta[sampling_seq,],ncol = 1), tau = matrix(all_chains[[1]]$post_samp$tau[sampling_seq,],ncol = num_switches))

initial_taus = all_chains[[1]]$initial_tau
accept_taus = apply(matrix(all_chains[[1]]$tau_accept[sampling_seq,], ncol = num_switches), 2,sum)/length(sampling_seq)

for( m in 2:num_chains){
	all_chains[[m]] = BMdrift_Meanswitch_contTau(mydata, num_switches,init_tau = 'random', cand_tau_step_per, iterations = iterations, warmup_per = warmup_per, min_dur = min_dur, plot_it = FALSE)
	initial_taus = rbind(initial_taus,all_chains[[m]]$initial_tau)
	accept_taus = rbind(accept_taus, apply(matrix(all_chains[[m]]$tau_accept[ sampling_seq,],ncol = num_switches), 2,sum)/length(sampling_seq))
	
	all_post[[m]] =list(lambda = all_chains[[m]]$post_samp$lambda[sampling_seq,], eta = matrix(all_chains[[m]]$post_samp$eta[sampling_seq,],ncol = 1), tau = matrix(all_chains[[m]]$post_samp$tau[sampling_seq,],ncol = num_switches))

if(plot_it == TRUE){	
	lambda_violin = plot_post_violin(all_chains[[m]]$post_samp$lambda, parname= c(paste("lambda", 1:(num_switches+1))), every_kth = every_kth)
	eta_violin = plot_post_violin(log10(all_chains[[m]]$post_samp$eta), parname= c(paste("log10eta", 1:1)),every_kth = every_kth)
	tau_violin = plot_post_violin(all_chains[[m]]$post_samp$tau, parname= c(paste("tau", 1:num_switches)), par_range = range(mydata$time), every_kth = every_kth)
	grid.arrange(tau_violin, lambda_violin, eta_violin, layout_matrix = cbind(c(1,1,1),c(2,2,3)), top = textGrob(paste("Chain ",m), gp = gpar(fontsize = 18)))
}

}


names(all_chains) = paste("chain", 1:num_chains, sep = '')
names(all_post) = paste("chain", 1:num_chains, sep = '')

colnames(initial_taus) = paste('tau', 1:num_switches, sep = '')
rownames(initial_taus) = names(all_post)
#print(initial_taus)

colnames(accept_taus) = paste('tau', 1:num_switches, sep = '')
rownames(accept_taus) = paste("chain", 1:num_chains, sep = '')
print("Acceptance Rate for tau")
print(accept_taus)
##-------------------------------------------
##Convergence statistics (Rhat and neff)
##-------------------------------------------

parnames = names(all_post[[1]])
Rhat_values = matrix(nrow = length(parnames), ncol = num_switches +1)
rownames(Rhat_values) = parnames
colnames(Rhat_values) = paste("state",1:(num_switches +1), sep = '')

neff_values = matrix(nrow = length(parnames), ncol = num_switches +1)
rownames(neff_values) = parnames
colnames(neff_values) = paste("state",1:(num_switches +1), sep = '')



pp = 0
for(pn in parnames){
	num_states = ncol(all_post$chain1[[pn]])
	pp = pp + 1
if(pn == 'tau'){
		for (st in 1:num_states){
		chain_mat= matrix(unlist(lapply(all_post, get_postsamp, parname = pn,state_index = st)), nrow = length(sampling_seq), ncol = num_chains)
		chain_mat =matrix(sapply(chain_mat, get_tau_index, mydata$time), ncol = num_chains)
		
		conv_stats = convergence_stats_fnc(chain_mat)
		
		Rhat_values[pp,st] = conv_stats$Rhat
		neff_values[pp,st] = conv_stats$neff
		
		}
	}else{
		for (st in 1:num_states){
		chain_mat= matrix(unlist(lapply(all_post, get_postsamp, parname = pn,state_index = st)), nrow = length(sampling_seq), ncol = num_chains)
		
		conv_stats = convergence_stats_fnc(chain_mat)
		
		Rhat_values[pp,st] = conv_stats$Rhat
		neff_values[pp,st] = conv_stats$neff
		
		}	
	} #checking if the parameter is tau	
		
		
} # End of the parameter loops
print("Potential Scale Reduction Factor (< 1.1)")
print(Rhat_values)
print("Number of Effective Samples (> 5*2*num_chains)")
print(neff_values)
return(list(post_samp= all_post,Rhat =  Rhat_values,neff = neff_values,init_tau = initial_taus, acceptance_tau = accept_taus))

} #End of the function


 

##=============================================
## Algorithm for Multiple Chains without Nefff
##=============================================



BMdrift_switchMean_chains_Rhat = function(mydata, num_switches, num_chains = 2, cand_tau_step_per = 0.05,min_dur = 2, iterations = 10000, warmup_per = 0.5,every_kth = 1,plot_it = FALSE){

if(num_chains == 1){
	stop_message = "Number of chains must be > 1"
	stop(stop_message) 
}


sampling_seq = seq(ceiling(iterations*warmup_per)+ every_kth, iterations, by = every_kth)

all_chains = list()
all_post = list()


all_chains[[1]] = BMdrift_Meanswitch_contTau(mydata, num_switches,init_tau = 'uniform',cand_tau_step_per,min_dur = min_dur,iterations =  iterations,warmup_per =  warmup_per, plot_it = FALSE)



if(plot_it == TRUE){
lambda_violin = plot_post_violin(all_chains[[1]]$post_samp$lambda, parname= c(paste("lambda", 1:(num_switches+1))), every_kth = every_kth)
eta_violin = plot_post_violin(matrix(log10(all_chains[[1]]$post_samp$eta), ncol = 1), parname= c(paste("log10eta", 1)), every_kth = every_kth)
tau_violin = plot_post_violin(all_chains[[1]]$post_samp$tau, parname= c(paste("tau", 1:num_switches)), par_range = range(mydata$time),every_kth = every_kth)
grid.arrange(tau_violin, lambda_violin, eta_violin, layout_matrix = cbind(c(1,1,1),c(2,2,3)), top = textGrob("Chain 1",gp = gpar(fontsize = 18)))
}




all_post[[1]] = list(lambda = all_chains[[1]]$post_samp$lambda[sampling_seq,], eta = matrix(all_chains[[1]]$post_samp$eta[sampling_seq,],ncol = 1), tau = matrix(all_chains[[1]]$post_samp$tau[sampling_seq,],ncol = num_switches))

initial_taus = all_chains[[1]]$initial_tau
accept_taus = apply(matrix(all_chains[[1]]$tau_accept[sampling_seq,], ncol = num_switches), 2,sum)/length(sampling_seq)

for( m in 2:num_chains){
	all_chains[[m]] = BMdrift_Meanswitch_contTau(mydata, num_switches,init_tau = 'random', cand_tau_step_per, iterations = iterations, warmup_per = warmup_per, min_dur = min_dur, plot_it = FALSE)
	initial_taus = rbind(initial_taus,all_chains[[m]]$initial_tau)
	accept_taus = rbind(accept_taus, apply(matrix(all_chains[[m]]$tau_accept[ sampling_seq,],ncol = num_switches), 2,sum)/length(sampling_seq))
	
	all_post[[m]] =list(lambda = all_chains[[m]]$post_samp$lambda[sampling_seq,], eta = matrix(all_chains[[m]]$post_samp$eta[sampling_seq,],ncol = 1), tau = matrix(all_chains[[m]]$post_samp$tau[sampling_seq,],ncol = num_switches))

if(plot_it == TRUE){	
	lambda_violin = plot_post_violin(all_chains[[m]]$post_samp$lambda, parname= c(paste("lambda", 1:(num_switches+1))), every_kth = every_kth)
	eta_violin = plot_post_violin(log10(all_chains[[m]]$post_samp$eta), parname= c(paste("log10eta", 1)),every_kth = every_kth)
	tau_violin = plot_post_violin(all_chains[[m]]$post_samp$tau, parname= c(paste("tau", 1:num_switches)), par_range = range(mydata$time), every_kth = every_kth)
	grid.arrange(tau_violin, lambda_violin, eta_violin, layout_matrix = cbind(c(1,1,1),c(2,2,3)), top = textGrob(paste("Chain ",m), gp = gpar(fontsize = 18)))
}

}


names(all_chains) = paste("chain", 1:num_chains, sep = '')
names(all_post) = paste("chain", 1:num_chains, sep = '')

colnames(initial_taus) = paste('tau', 1:num_switches, sep = '')
rownames(initial_taus) = names(all_post)

colnames(accept_taus) = paste('tau', 1:num_switches, sep = '')
rownames(accept_taus) = paste("chain", 1:num_chains, sep = '')
print("Acceptance Rate for tau")
print(accept_taus)
##-------------------------------------------
##Convergence statistics (Rhat)
##-------------------------------------------

parnames = names(all_post[[1]])
Rhat_values = matrix(nrow = length(parnames), ncol = num_switches +1)
rownames(Rhat_values) = parnames
colnames(Rhat_values) = paste("state",1:(num_switches +1), sep = '')

pp = 0
for(pn in parnames){
	num_states = ncol(all_post$chain1[[pn]])
	pp = pp + 1
if(pn == 'tau'){
		for (st in 1:num_states){
		chain_mat= matrix(unlist(lapply(all_post, get_postsamp, parname = pn,state_index = st)), nrow = length(sampling_seq), ncol = num_chains)
		chain_mat =matrix(sapply(chain_mat, get_tau_index, mydata$time), ncol = num_chains)
		
		Rhat_values[pp,st] = Rhat_fnc(chain_mat)
		
		}
	}else{
		for (st in 1:num_states){
		chain_mat= matrix(unlist(lapply(all_post, get_postsamp, parname = pn,state_index = st)), nrow = length(sampling_seq), ncol = num_chains)
				
		Rhat_values[pp,st] = Rhat_fnc(chain_mat)
		
		}	
	} #checking if the parameter is tau	
		
		
} # End of the parameter loops






print("Potential Scale Reduction Factor (< 1.1)")
print(Rhat_values)
return(list(post_samp= all_post,Rhat =  Rhat_values,init_tau = initial_taus, acceptance_tau = accept_taus))

} #End of the function


 




##================================================
## Helper Functions
##=================================================


##-----------------------------------------------------
## Functions to help with lists
##-----------------------------------------------------


col_to_list = function(matrix){
	lapply(seq_len(ncol(matrix)), function(i) matrix[,i] )
}

sum_diff_range = function(vector, index){
	return(sum(diff(vector[index])))
}


get_postsamp = function(post_samples,parname, state_index){
	return(post_samples[[parname]][,state_index])
}

get_tau_index = function(tau, time_seq){
	if(tau <min(time_seq)){
		return(1)
	}else{return(max(which(time_seq - tau <= 0)))}
}



##-----------------------------------------------------
## Sampling Functions
##-----------------------------------------------------


rnorm_list = function(n, pars){
	return(rnorm(n = 1, mean = pars[1], sd = sqrt(pars[2])))
}

rgamma_list = function(n, pars){
	return(rgamma(n = 1, shape = pars[1], rate=pars[2]))
}

sampler_uniform = function(current, step){
	return(runif(n=1, min = current -step,max = current+step))
}


##-----------------------------------------------------
## Log likelihoods
##-----------------------------------------------------



ll_switch_interval = function(time, Xn, taus, lambdas, etas){
	
	num_per_state = diff(taus) 
	state_1_index = (taus[1]+1):taus[2]
	state_2_index = (taus[2]+1):taus[3]

	Delta_n1 = time[state_1_index] - time[state_1_index - 1]

	ll_1 = (num_per_state[1]/2)*(log(etas[1]) - log(2*pi)) - (1/2)*sum(log(Delta_n1))-(etas[1]/2)*sum(((Xn[state_1_index]- Xn[(state_1_index -1)] - Delta_n1*lambdas[1])^2)/Delta_n1)
	
	Delta_n2 = time[state_2_index] - time[state_2_index - 1]

	ll_2 = (num_per_state[2]/2)*(log(etas[2]) - log(2*pi)) - (1/2)*sum(log(Delta_n2))-(etas[2]/2)*sum(((Xn[state_2_index]- Xn[(state_2_index) -1] - Delta_n2*lambdas[2])^2)/Delta_n2)

	return(ll_1 + ll_2)

}



##-----------------------------------------------------
## Convergence Statistic
##-----------------------------------------------------

Rhat_fnc = function(post_matrix){
	num_samples  = nrow(post_matrix)
	
	first_half = 1:floor(num_samples/2); second_half = (floor(num_samples/2)+1):num_samples
	 num_split_samp = length(first_half)
	
	
	first_mat = post_matrix[first_half, ];second_mat = post_matrix[second_half, ]
	
	num_chains  = 2*ncol(post_matrix)

	chain_mean = c(apply(first_mat, 2, mean),apply(second_mat, 2, mean))
	grand_mean = mean(post_matrix)

	Between_var = (num_split_samp/(num_chains-1))*sum((chain_mean - rep(grand_mean, length(chain_mean)))^2)
	
	Within_var = mean(c(apply(first_mat, 2, var),apply(second_mat, 2, var)))
	
	Var_est = ((num_split_samp-1)/num_split_samp)*Within_var + (1/num_split_samp)*Between_var
	
	return(sqrt(Var_est/ Within_var))
}



variogram_fnc = function(post_matrix, lag_t){
	if(is.matrix(post_matrix) == FALSE){
		stop("Posterior Samples need to be in a matrix with (i,j)th entry is the ith sample from the jth chain")
	}
	
	num_chains = ncol(post_matrix)
	num_lags =nrow(post_matrix) - lag_t
	return((1/num_chains)*(1/num_lags)*sum(apply(post_matrix, 2,diff, lag = lag_t)^2))	
}


convergence_stats_fnc = function(post_matrix){
	
	if(is.matrix(post_matrix) == FALSE){
		stop("Posterior Samples need to be in a matrix with (i,j)th entry is the ith sample from the jth chain")
	}
	
	
## To calculate the variance of the samples	
	num_samples  = nrow(post_matrix)
	
	first_half = 1:floor(num_samples/2); second_half = (floor(num_samples/2)+1):num_samples
	 num_split_samp = length(first_half)
	num_chains  = 2*ncol(post_matrix)
	
	first_mat = post_matrix[first_half, ];second_mat = post_matrix[second_half, ]
	
	

	chain_mean = c(apply(first_mat, 2, mean),apply(second_mat, 2, mean))
	grand_mean = mean(post_matrix)

	Between_var = (num_split_samp/(num_chains-1))*sum((chain_mean - rep(grand_mean, length(chain_mean)))^2)
	
	Within_var = mean(c(apply(first_mat, 2, var),apply(second_mat, 2, var)))
	
	Var_est = ((num_split_samp-1)/num_split_samp)*Within_var + (1/num_split_samp)*Between_var


## Rhat Statistic	
	Rhat = sqrt(Var_est/ Within_var)	
	
## N effective - only makes sense to compute when the chain is well mixed
	
	if(Rhat <=1.1){
	
	rho_hat_t = 1-(sapply(1:num_split_samp, variogram_fnc, post_matrix = post_matrix)/(2*Var_est))
	
	odds_seq = seq(1, num_split_samp-2, by = 2)	
		
	lag_T = min(odds_seq[which(rho_hat_t[odds_seq + 1] + rho_hat_t[odds_seq + 2] < 0)], num_split_samp)
	print(lag_T)
	if(lag_T == num_split_samp){print(paste("T = ", num_split_samp))}
	
	neff = (num_chains*num_split_samp)/(1 + 2*sum(rho_hat_t[1:lag_T]))
	}else{
		neff= NA	
		}
	
	return(list(Rhat = Rhat, neff = neff))
}






