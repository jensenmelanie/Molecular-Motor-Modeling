

library(mvtnorm)

library(grid)
library(gridExtra)
library(ggplot2)
library(RColorBrewer)
mellow.color.pal = colorRampPalette(rev(brewer.pal(11,'Spectral')))


##============================================================
## Computing the Bayes Model Section statistics
##============================================================


bayes_stats_MCMC_FDR_kswitch = function(Xn, num_post_samp,sampling_pars){
	N = length(Xn)

	if((num_post_samp %% sampling_pars$num_chains == 0) == FALSE){
		num_post_samp = ceiling(num_post_samp/sampling_pars$num_chains)*sampling_pars$num_chains
		print(paste('Number of samples increased to ', num_post_samp))
	}


##Null MODEL-------------------------------------------------------------
if(is.na(sampling_pars$nullK)== TRUE){
	sampling_pars$nullK == 0
}

if(sampling_pars$nullK == 0){
	post_samp_null = list()
	var_theta = 	var(Xn)/N; mu_theta = mean(Xn)
	theta_null = rt(num_post_samp, df = N-1)*sqrt(var_theta) + mu_theta
	post_samp_null$theta = matrix(theta_null, nrow = num_post_samp, ncol = 1)
	
	null_rates = sapply(theta_null, function(theta){sum((Xn- theta)^2)/2})
	post_samp_null$sigma_sq = matrix(1/sapply(null_rates, rgamma, n = 1, shape = N/2),nrow = num_post_samp, ncol = 1)
	Ell_null = Ell_BM(Xn, post_samp_null,num_switch_pts = 0)

	PBS_null = PBS_BM(Xn, post_samp_null)
	lPBS_null = log10( PBS_null[1])
	WAIC_null = PBS_null[2]	
	converge_null = TRUE
} else{
	
	MCMC = get_post_samp_MCMC(Xn, num_post_samp, num_switches = sampling_pars$nullK, sampling_pars)
	
	PBS_null = PBS_BM(Xn, MCMC$post_samp, num_switch_pts = sampling_pars$nullK)
	lPBS_null = log10(PBS_null[1])
	Ell_null = Ell_BM(Xn, MCMC$post_samp, num_switch_pts = sampling_pars$nullK)
	WAIC_null = PBS_null[2]
	converge_null = MCMC$converge
	} #End of the null loop

##-------------MODEL WITH k SWITCH----------------------------
	
	
	if( sampling_pars$num_switches == 0){
		post_samp_k= list()
		var_theta = var(Xn)/N; mu_theta = mean(Xn)
		theta_k = rt(num_post_samp, df = N-1)*sqrt(var_theta) + mu_theta
		post_samp_k$theta = matrix(theta_k, nrow = num_post_samp, ncol = 1)
	
		k_rates = sapply(theta_k, function(theta){sum((Xn- theta)^2)/2})
		post_samp_k$sigma_sq = matrix(1/sapply(k_rates, rgamma, n = 1, shape = N/2),nrow = num_post_samp, ncol = 1)
		
		Ell_k = Ell_BM(Xn, post_samp_k,num_switch_pts = 0)
		PBS_k = PBS_BM(Xn, post_samp_k, num_switch_pts = 0)
		converge_k = TRUE
		
	
	}else{
		MCMCk =  get_post_samp_MCMC(Xn, num_post_samp, num_switches = sampling_pars$num_switches, sampling_pars)
		
		converge_k = MCMCk$converge 
		
		PBS_k = PBS_BM(Xn, MCMCk$post_samp, num_switch_pts = sampling_pars$num_switches)
		Ell_k = Ell_BM(Xn, MCMCk$post_samp, num_switch_pts = sampling_pars$num_switches)
		WAIC_k = PBS_k[2]

	}
	

	return(list(lPBF= log10(PBS_k[1]) - lPBS_null, Ell = Ell_k- Ell_null, WAIC = c( WAIC_null,PBS_k[2]), converge = c(converge_null, converge_k) ))

}


##============================================================
## get_posterior samples function
##============================================================


get_post_samp_MCMC = function(Xn, num_post_samp,num_switches, sampling_pars ){ 
	post_samp= list()
	post_samp$tau = matrix(nrow = num_post_samp, ncol = num_switches)
	post_samp$theta = matrix(nrow = num_post_samp, ncol = num_switches + 1)
	post_samp$sigma_sq = matrix(nrow = num_post_samp, ncol = 1)
	
	alg_converge = TRUE
	num_good = FALSE; num_trials = 0
	while( num_good == FALSE){
		num_trials = num_trials + 1
		draw_samp = Norm_switchMean_chains(Xn, num_switches = num_switches, sampling_pars$num_chains, sampling_pars$cand_tau_step_per, sampling_pars$min_dur, sampling_pars$iterations, sampling_pars$warmup_per, sampling_pars$every_kth[1])
		
		empty_index = which(is.na(draw_samp$Rhat) == TRUE)
		num_par = length(draw_samp$Rhat[-empty_index])
		num_Rhat_good = sum(draw_samp$Rhat[-empty_index] <= 1.1)
		
		neff_empty_index = which(is.na(draw_samp$neff) == TRUE)
		num_neff_good = sum(as.numeric(draw_samp$neff[-neff_empty_index] > (5*2* sampling_pars$num_chains)))
		
		ind_conv = as.numeric(num_Rhat_good == num_par) + as.numeric(num_neff_good == num_par)
		#print(ind_conv)
		
		if(ind_conv == 2){
			num_good = TRUE
			num_samp = nrow(draw_samp$post_samp[[1]][[1]])
			seq_k = floor(seq(1, num_samp, length = floor(num_post_samp/sampling_pars$num_chains)))
			
			tau_map = c()
			for(j in 1:(num_switches)){
				current_tau = c((sapply(1: sampling_pars$num_chains, function(index){draw_samp$post_samp[[index]]$tau[,j]}))[seq_k,])
				post_samp$tau[,j] = floor(current_tau)
				tau_map = c(tau_map, (density(current_tau)$x)[which.max(density(current_tau)$y)])	
			}
			
			for(j in 1:(num_switches + 1)){
				post_samp$theta[,j] = c((sapply(1: sampling_pars$num_chains, function(index){draw_samp$post_samp[[index]]$theta[,j]}))[seq_k,])
				}
		
		post_samp$sigma_sq[,1] =1/c((sapply(1:sampling_pars$num_chains, function(index){draw_samp$post_samp[[index]]$eta}))[seq_k,])
	
		} #end of setting samples
		
		
	if(num_trials == 2){
		num_good = TRUE
		alg_converge = FALSE
		tau_map = NA
		
			num_samp = nrow(draw_samp$post_samp[[1]][[1]])
			seq_k = floor(seq(1, num_samp, length = floor(num_post_samp/sampling_pars$num_chains)))
			
			tau_map = c()
			for(j in 1:(num_switches)){
				current_tau = c((sapply(1: sampling_pars$num_chains, function(index){draw_samp$post_samp[[index]]$tau[,j]}))[seq_k,])
				post_samp$tau[,j] = floor(current_tau)
				tau_map = c(tau_map, (density(current_tau)$x)[which.max(density(current_tau)$y)])	
			}
			
			for(j in 1:(num_switches + 1)){
				post_samp$theta[,j] = c((sapply(1: sampling_pars$num_chains, function(index){draw_samp$post_samp[[index]]$theta[,j]}))[seq_k,])
				}
		
		post_samp$sigma_sq[,1] =1/c((sapply(1:sampling_pars$num_chains, function(index){draw_samp$post_samp[[index]]$eta}))[seq_k,])
	
	} # End of the break if it has 2 tries		
		
	
	
	
	} # End of the while loop

	return(list(post_samp = post_samp, converge = alg_converge, tau_map = tau_map ))
	
	
	}



 
##================================================
## SAMPLING Algorithm Function
##=================================================

Norm_Meanswitch_contTau = function(Xin, num_switches,init_tau = 'uniform', cand_tau_step_per = 0.2,min_dur = 2,iterations = 4000, warmup_per = 0.5,plot_it = TRUE){

N = length(Xin)
num_states = num_switches + 1

if(num_states*(min_dur+1)>= N){
	stop("Not enough observations for each state to be observed for the given number of minimum observations")
}


##---------------------------------------------------------------------
## Storing the posterior samples
##---------------------------------------------------------------------
tau_support = c((min_dur+1),(N-min_dur+1))
## we add one because we want 10 increments per state

post_samp = list()
post_samp$theta = matrix(nrow = iterations, ncol = num_states)
post_samp$eta = matrix(nrow = iterations, ncol = 1)
post_samp$tau = matrix(nrow = iterations, ncol = num_switches)

overlapping_intervals= matrix(nrow = iterations, ncol = num_switches)
accept_rates = matrix(nrow = iterations, ncol = num_switches)

##---------------------------------------------------------------------
## Initializing
##---------------------------------------------------------------------
if(init_tau == 'uniform'){
	initial_tau = diff(range(tau_support))*((1:num_switches)/num_states)
	post_samp$tau[1,] = initial_tau
}else{
	
	initial_tau = runif(n= 1, min = tau_support[1], max = N -(min_dur+1)*num_switches )

	if(num_switches >1){
		for(j in 1:(num_switches-1)){
			initial_tau = c(initial_tau, runif(n =1, min = initial_tau[j], max = N- (min_dur+1)*(num_switches -j)))
			}	
	}
	post_samp$tau[1,] = initial_tau
}


initial_theta = rnorm(n = num_states, mean  = 2, sd = 0.3)
post_samp$theta[1,] = initial_theta
initial_eta = rgamma(n = 1, shape = .1, rate = .1)
post_samp$eta[1,] = initial_eta

cand_var_tau = ceiling(N*cand_tau_step_per)

if(length(cand_var_tau) == 1){
	cand_var_tau = rep(cand_var_tau, num_switches)	
}else if(length(cand_var_tau)!= num_switches){
	stop("The chosen cand_var_tau needs to be length 1 or number of switch points")
}

##---------------------------------------------------------------------
## Sampling
##---------------------------------------------------------------------

for( it in 2:iterations){

tau_vec_it =c(0, post_samp$tau[it-1,], N)

tau_index = floor(post_samp$tau[it-1, ])
tau_index_vec_it = c(0,tau_index, N)

state_list = list()
Xin_st = list()


## We are assuming that the switch point occrs at n_tau

for(st in 1:num_states){
	state_list[[st]] = (tau_index_vec_it[st] + 1): tau_index_vec_it[st+1]	
	Xin_st[[st]] = Xin[state_list[[st]]]
	}




##-----------------------------eta block-----------------------------
## We are assuming that eta stays the same for each state
eta_post_alpha = N/2 
eta_post_beta_st = c()

for(st in 1:num_states){
	eta_post_beta_st = c(eta_post_beta_st,(Xin_st[[st]] - post_samp$theta[it-1,st])^2)
}

eta_post_beta = (1/2)*sum(eta_post_beta_st)

post_samp$eta[it,] = rgamma(n= 1, shape = eta_post_alpha, rate = eta_post_beta)


##-----------------------------theta block-----------------------------

## Jeffreys prior (ie flat on lambda)



theta_post_var = (lengths(state_list)*post_samp$eta[it,])^(-1)
theta_post_mean = unlist(lapply(Xin_st, sum))/lengths(state_list)

post_samp$theta[it,] = unlist(lapply(col_to_list(rbind(theta_post_mean,theta_post_var)), rnorm_list, n = 1))

##-----------------------------tau block-----------------------------

for(st in 1:num_switches){
	
	tau_loop_vec = tau_vec_it[st:(st+2)]
	tau_index_loop_vec = tau_index_vec_it[st:(st+2)]

	cand_tau = sampler_uniform(tau_loop_vec[2], cand_var_tau[st])
	cand_tau_vec = tau_loop_vec; cand_tau_vec[2] = cand_tau
	cand_tau_index_vec = floor(cand_tau_vec)
	
	overlapping_indicator = as.numeric(cand_tau_index_vec[2]<= (cand_tau_index_vec[1]+min_dur -1) ) + as.numeric(cand_tau_index_vec[2] >=(cand_tau_index_vec[3]-min_dur+1))+ as.numeric(cand_tau <= tau_support[1]) + as.numeric(cand_tau >= tau_support[2])
	
	 #overlapping_indicator = as.numeric(cand_tau<= mydata$time[cand_tau_index_vec[1]+min_dur +1] ) +  as.numeric(cand_tau >= mydata$time[cand_tau_index_vec[3]-min_dur+1]) + as.numeric(cand_tau <= tau_support[1]) + as.numeric(cand_tau >= tau_support[2])
	
	if( overlapping_indicator > 0){
		ratio = 0; overlapping_intervals[it, st] = 1
	}else{
	
		switch_thetas = post_samp$theta[it,c(st,st+1)]; 
		switch_etas = rep(post_samp$eta[it,], time= 2)
		

		log_like_ratio = ll_Nswitch_interval(Xin, cand_tau_index_vec, switch_thetas, switch_etas) - ll_Nswitch_interval(Xin, tau_index_loop_vec, switch_thetas, switch_etas)
				
		ratio = exp(log_like_ratio)	
		
	} #End of get the ratio
	
	
	accept_fnc_tau = min(1, ratio)
	
	
	if(	runif(1,min = 0, max = 1) <= accept_fnc_tau){
		post_samp$tau[it, st] = cand_tau; accept_rates[it,st] = 1
		tau_vec_it[st+1] = cand_tau
	}else {
		post_samp$tau[it, st] = post_samp$tau[it-1,st]; accept_rates[it,st] = 0
	}

	
} # End of the tau loop



} # End of the iterations loop

return(list(post_samp= post_samp, tau_accept = accept_rates, initial_tau = initial_tau))

} #End of the function





##=============================================
## Algorithm for Multiple Chains with Nefff
##=============================================


Norm_switchMean_chains = function(Xin, num_switches, num_chains = 2, cand_tau_step_per = 0.1,min_dur = 2, iterations = 10000, warmup_per = 0.5,every_kth = 1,plot_it = FALSE){


if(num_chains == 1){
	stop_message = "Number of chains must be > 1"
	stop(stop_message) 
}



sampling_seq = seq(ceiling(iterations*warmup_per)+ every_kth, iterations, by = every_kth)


all_chains = list()
all_post = list()


all_chains[[1]] = Norm_Meanswitch_contTau(Xin, num_switches,init_tau = 'uniform',cand_tau_step_per,min_dur = min_dur,iterations =  iterations,warmup_per =  warmup_per, plot_it = FALSE)



if(plot_it == TRUE){
theta_violin = plot_post_violin(all_chains[[1]]$post_samp$theta, parname= c(paste("theta", 1:(num_switches+1))), every_kth = every_kth)
eta_violin = plot_post_violin(matrix(log10(all_chains[[1]]$post_samp$eta), ncol = 1), parname= c(paste("log10eta", 1)), every_kth = every_kth)
tau_violin = plot_post_violin(all_chains[[1]]$post_samp$tau, parname= c(paste("tau", 1:num_switches)),every_kth = every_kth,par_range = c(1, N))
grid.arrange(tau_violin, theta_violin, eta_violin, layout_matrix = cbind(c(1,1,1),c(2,2,3)), top = textGrob("Chain 1",gp = gpar(fontsize = 18)))
}


all_post[[1]] = list(theta = all_chains[[1]]$post_samp$theta[sampling_seq,], eta = matrix(all_chains[[1]]$post_samp$eta[sampling_seq,],ncol = 1), tau = matrix(all_chains[[1]]$post_samp$tau[sampling_seq,],ncol = num_switches))

initial_taus = all_chains[[1]]$initial_tau
accept_taus = apply(matrix(all_chains[[1]]$tau_accept[sampling_seq,], ncol = num_switches), 2,sum)/length(sampling_seq)

for( m in 2:num_chains){
	all_chains[[m]] =Norm_Meanswitch_contTau(Xin, num_switches,init_tau = 'random',cand_tau_step_per,min_dur = min_dur,iterations =  iterations,warmup_per =  warmup_per, plot_it = FALSE)	
	initial_taus = rbind(initial_taus,all_chains[[m]]$initial_tau)
	accept_taus = rbind(accept_taus, apply(matrix(all_chains[[m]]$tau_accept[ sampling_seq,],ncol = num_switches), 2,sum)/length(sampling_seq))
	
	all_post[[m]] =list(theta = all_chains[[m]]$post_samp$theta[sampling_seq,], eta = matrix(all_chains[[m]]$post_samp$eta[sampling_seq,],ncol = 1), tau = matrix(all_chains[[m]]$post_samp$tau[sampling_seq,],ncol = num_switches))

if(plot_it == TRUE){	
	theta_violin = plot_post_violin(all_chains[[m]]$post_samp$theta, parname= c(paste("theta", 1:(num_switches+1))), every_kth = every_kth)
	eta_violin = plot_post_violin(log10(all_chains[[m]]$post_samp$eta), parname= c(paste("log10eta", 1:1)),every_kth = every_kth)
	tau_violin = plot_post_violin(all_chains[[m]]$post_samp$tau, parname= c(paste("tau", 1:num_switches)), every_kth = every_kth,par_range = c(1, N))
	grid.arrange(tau_violin, theta_violin, eta_violin, layout_matrix = cbind(c(1,1,1),c(2,2,3)), top = textGrob(paste("Chain ",m), gp = gpar(fontsize = 18)))
}

}


names(all_chains) = paste("chain", 1:num_chains, sep = '')
names(all_post) = paste("chain", 1:num_chains, sep = '')

colnames(initial_taus) = paste('tau', 1:num_switches, sep = '')
rownames(initial_taus) = names(all_post)
#print(initial_taus)

colnames(accept_taus) = paste('tau', 1:num_switches, sep = '')
rownames(accept_taus) = paste("chain", 1:num_chains, sep = '')
#print("Acceptance Rate for tau")
#print(accept_taus)
##-------------------------------------------
##Convergence statistics (Rhat and neff)
##-------------------------------------------

parnames = names(all_post[[1]])
Rhat_values = matrix(nrow = length(parnames), ncol = num_switches +1)
rownames(Rhat_values) = parnames
colnames(Rhat_values) = paste("state",1:(num_switches +1), sep = '')

neff_values = matrix(nrow = length(parnames), ncol = num_switches +1)
rownames(neff_values) = parnames
colnames(neff_values) = paste("state",1:(num_switches +1), sep = '')



pp = 0
for(pn in parnames){
	num_states = ncol(all_post$chain1[[pn]])
	pp = pp + 1
if(pn == 'tau'){
		for (st in 1:num_states){
		chain_mat= matrix(unlist(lapply(all_post, get_postsamp, parname = pn,state_index = st)), nrow = length(sampling_seq), ncol = num_chains)
				
		conv_stats = convergence_stats_fnc(chain_mat)
		
		Rhat_values[pp,st] = conv_stats$Rhat
		neff_values[pp,st] = conv_stats$neff
		
		}
	}else{
		for (st in 1:num_states){
		chain_mat= matrix(unlist(lapply(all_post, get_postsamp, parname = pn,state_index = st)), nrow = length(sampling_seq), ncol = num_chains)
		
		conv_stats = convergence_stats_fnc(chain_mat)
		
		Rhat_values[pp,st] = conv_stats$Rhat
		neff_values[pp,st] = conv_stats$neff
		
		}	
	} #checking if the parameter is tau	
		
		
} # End of the parameter loops
#print("Potential Scale Reduction Factor (< 1.1)")
#print(Rhat_values)
#print("Number of Effective Samples (> 5*2*num_chains)")
#print(neff_values)
return(list(post_samp= all_post,Rhat =  Rhat_values,neff = neff_values,init_tau = initial_taus, acceptance_tau = accept_taus))

} #End of the function




##================================================
## Sampling Algorithm Helper Functions
##=================================================


##-----------------------------------------------------
## Functions to help with lists
##-----------------------------------------------------


col_to_list = function(matrix){
	lapply(seq_len(ncol(matrix)), function(i) matrix[,i] )
}

sum_diff_range = function(vector, index){
	return(sum(diff(vector[index])))
}


get_postsamp = function(post_samples,parname, state_index){
	return(post_samples[[parname]][,state_index])
}

##-----------------------------------------------------
## Sampling Functions
##-----------------------------------------------------


rnorm_list = function(n, pars){
	return(rnorm(n = 1, mean = pars[1], sd = sqrt(pars[2])))
}

rgamma_list = function(n, pars){
	return(rgamma(n = 1, shape = pars[1], rate=pars[2]))
}

sampler_uniform = function(current, step){
	return(runif(n=1, min = current -step,max = current+step))
}


##-----------------------------------------------------
## Log likelihoods
##-----------------------------------------------------


ll_Nswitch_interval = function(Xin, taus, thetas, etas){
	
	num_per_state = diff(taus) 
	state_1_index = (taus[1]+1):taus[2]
	state_2_index = (taus[2]+1):taus[3]


	ll_1 = (num_per_state[1]/2)*(log(etas[1]) - log(2*pi)) -(etas[1]/2)*sum((Xin[state_1_index] - thetas[1])^2)
	

	ll_2 = (num_per_state[2]/2)*(log(etas[2]) - log(2*pi)) -(etas[2]/2)*sum((Xin[state_2_index] - thetas[2])^2)

	return(ll_1 + ll_2)

}



##-----------------------------------------------------
## Algorithm Convergence Statistic
##-----------------------------------------------------

Rhat_fnc = function(post_matrix){
	num_samples  = nrow(post_matrix)
	
	first_half = 1:floor(num_samples/2); second_half = (floor(num_samples/2)+1):num_samples
	 num_split_samp = length(first_half)
	
	
	first_mat = post_matrix[first_half, ];second_mat = post_matrix[second_half, ]
	
	num_chains  = 2*ncol(post_matrix)

	chain_mean = c(apply(first_mat, 2, mean),apply(second_mat, 2, mean))
	grand_mean = mean(post_matrix)

	Between_var = (num_split_samp/(num_chains-1))*sum((chain_mean - rep(grand_mean, length(chain_mean)))^2)
	
	Within_var = mean(c(apply(first_mat, 2, var),apply(second_mat, 2, var)))
	
	Var_est = ((num_split_samp-1)/num_split_samp)*Within_var + (1/num_split_samp)*Between_var
	
	return(sqrt(Var_est/ Within_var))
}



variogram_fnc = function(post_matrix, lag_t){
	if(is.matrix(post_matrix) == FALSE){
		stop("Posterior Samples need to be in a matrix with (i,j)th entry is the ith sample from the jth chain")
	}
	
	num_chains = ncol(post_matrix)
	num_lags =nrow(post_matrix) - lag_t
	return((1/num_chains)*(1/num_lags)*sum(apply(post_matrix, 2,diff, lag = lag_t)^2))	
}


convergence_stats_fnc = function(post_matrix){
	
	if(is.matrix(post_matrix) == FALSE){
		stop("Posterior Samples need to be in a matrix with (i,j)th entry is the ith sample from the jth chain")
	}
	
	
## To calculate the variance of the samples	
	num_samples  = nrow(post_matrix)
	
	first_half = 1:floor(num_samples/2); second_half = (floor(num_samples/2)+1):num_samples
	 num_split_samp = length(first_half)
	num_chains  = 2*ncol(post_matrix)
	
	first_mat = post_matrix[first_half, ];second_mat = post_matrix[second_half, ]
	
	

	chain_mean = c(apply(first_mat, 2, mean),apply(second_mat, 2, mean))
	grand_mean = mean(post_matrix)

	Between_var = (num_split_samp/(num_chains-1))*sum((chain_mean - rep(grand_mean, length(chain_mean)))^2)
	
	Within_var = mean(c(apply(first_mat, 2, var),apply(second_mat, 2, var)))
	
	Var_est = ((num_split_samp-1)/num_split_samp)*Within_var + (1/num_split_samp)*Between_var


## Rhat Statistic	
	Rhat = sqrt(Var_est/ Within_var)	
	
## N effective - only makes sense to compute when the chain is well mixed
	
	if(Rhat <=1.1){
	
	rho_hat_t = 1-(sapply(1:num_split_samp, variogram_fnc, post_matrix = post_matrix)/(2*Var_est))
	
	odds_seq = seq(1, num_split_samp-2, by = 2)	
		
	lag_T = min(odds_seq[which(rho_hat_t[odds_seq + 1] + rho_hat_t[odds_seq + 2] < 0)], num_split_samp)
	#print(lag_T)
	if(lag_T == num_split_samp){print(paste("T = ", num_split_samp))}
	
	neff = (num_chains*num_split_samp)/(1 + 2*sum(rho_hat_t[1:lag_T]))
	}else{
		neff= NA	
		}
	
	return(list(Rhat = Rhat, neff = neff))
}



##---------------------------------
##Posterior Sample Violin plots
##--------------------------------
plot_post_violin = function(post_samp, parname, par_range= NA, every_kth = 1, warmup = 0.5){

num_samples = nrow(post_samp)
num_par = ncol(post_samp)

every_kth_index = seq(ceiling(warmup*num_samples)+1, num_samples, by= every_kth)
num_samp_k = length(every_kth_index)


my_colors = mellow.color.pal(num_par +2)
	if(sum(as.numeric(my_colors == "#FFFFBF")) >0 ){
		my_colors = my_colors[- which(my_colors == "#FFFFBF")]
	}else{
		my_colors = my_colors[1:(num_par +1)]
	}

par_lab = 1:num_par
par_mat = cbind(rep(par_lab,  each =num_samp_k ),c(post_samp[every_kth_index,]))
par_data = data.frame(group = par_mat[,1], value = par_mat[,2])

if(is.na(par_range[1]) == TRUE){
	par_range = range(par_data['value'])
}

 ggplot(par_data, aes(x = as.factor(group), y = value, fill = as.factor(group))) + geom_violin()  + scale_fill_manual(values = my_colors, name = "Parameter", labels = parname)  + labs(y = "Parameter Value", x = "State Index") + labs(title = "Posterior Sample Violin Plot") + ylim(par_range[1], par_range[2])


} #End of function


##============================================================
## Model Comparison Statistics
##============================================================


row_to_list = function(matrix){
	lapply(seq_len(nrow(matrix)), function(i) matrix[i,] )
}


every_kth_entry = function(matrix, every_kth = 1, burn_in_per = 0.5){
	mat_dim = dim(matrix)
	to_take_index = seq((ceiling(nrow(matrix)*burn_in_per) + every_kth), nrow(matrix), by = every_kth)
	if(mat_dim[2] == 1){
		return(matrix(matrix[to_take_index,], ncol = 1))
	}else{
		return(matrix[to_take_index,])
		}
}


##-------------------------------------------------------------------
## log likelihoods functions
##-------------------------------------------------------------------


ll_BM= function(Xn, pars){
	num_obs = length(Xn)
	mu = pars[1]; sigma_sq = pars[2]
	
	return(-(num_obs/2)*log(2*pi*sigma_sq) - (1/(2*sigma_sq))*sum((Xn - mu)^2))
}



ll_BMswitch = function(Xn, taus, thetas, sigma_sq){
	num_obs = length(Xn)
	num_switch = length(taus); num_states = num_switch + 1

	num_per_state = diff(c(0,taus,length(Xn))) 
	thetas_vec = c(rep(thetas, times = num_per_state))

	return(-sum((num_per_state/2)*log(2*pi*sigma_sq))- (1/(2*sigma_sq))*sum((Xn -thetas_vec)^2))
}


##-------------------------------------------------------------------
## AMOC Functions
##-------------------------------------------------------------------
unscale_var = function(Xn, lower, upper){
	return(sum((Xn[lower:upper]- mean(Xn[lower:upper]))^2)	)
}



AMOC_single = function(Xn, tau){
	num_obs = length(Xn)
	H_tau = (unscale_var(Xn, 1, tau) + unscale_var(Xn, tau+1, num_obs))/ num_obs
	return(((num_obs)/(tau*(num_obs - tau)))*(sum(Xn[1:tau]) -(tau/num_obs)*sum(Xn))^2*(1/H_tau))
}

AMOC_stat = function(Xn){
	num_obs = length(Xn)
	test_stat = sqrt(max(sapply(1:(num_obs-1), AMOC_single, Xn = Xn)))
	tau_opt = (1:(num_obs-1))[min(which.max(sapply(1:(num_obs-1), AMOC_single, Xn = Xn)))]
	return(list(stat = test_stat, tau_est = tau_opt))
	}

##-------------------------------------------------------------------
##Posterior Bayes Score
##-------------------------------------------------------------------

PBS_BM = function(Xn, post_samples, num_switch_pts = 0){
	

	if(num_switch_pts == 0){
		
		par_mat = cbind(post_samples[["theta"]], post_samples[["sigma_sq"]])
		par_list = lapply(seq_len(nrow(par_mat)), function(i) par_mat[i,] )
		
		lppd = unlist(lapply(par_list,  ll_BM,  Xn =Xn))
		PBF = mean(exp(lppd))
		WAIC = -2*(log(PBF) - var(lppd))
		#print(var(lppd))

		return(	c(PBF, WAIC))	
		
				
	}else if(num_switch_pts == 1){

		num_samps = nrow(post_samples[[1]])

		ll_n = c()
		for(nn in 1:num_samps){
			ll_n = c(ll_n,	ll_BMswitch(Xn, post_samples[["tau"]][nn], post_samples[["theta"]][nn,], post_samples[["sigma_sq"]][nn,]) )	
		}
		
		PBF = mean(exp(ll_n))
		WAIC = -2*(log(PBF) - var(ll_n))
		#print(var(ll_n))

		return(	c(PBF, WAIC))		

		
		}else{
		
		num_samps = nrow(post_samples[[1]])

		ll_n = c()
		for(nn in 1:num_samps){
			ll_n = c(ll_n,	ll_BMswitch(Xn, post_samples[["tau"]][nn,], post_samples[["theta"]][nn,], post_samples[["sigma_sq"]][nn,]) )	
		}
		PBF = mean(exp(ll_n))
		WAIC = -2*(log(PBF) - var(ll_n))
		#print(var(ll_n))
		return(	c(PBF, WAIC))	
	}
	
}


##-------------------------------------------------------------------
## mean Lppd
##-------------------------------------------------------------------

Ell_BM = function(Xn, post_samples, num_switch_pts = 0 ){
	

	if(num_switch_pts == 0){
		
	
		par_mat = cbind(post_samples[["theta"]], post_samples[["sigma_sq"]])
		par_list = lapply(seq_len(nrow(par_mat)), function(i) par_mat[i,] )
		
		
		return(mean(unlist(lapply(par_list,  ll_BM,  Xn =Xn))))
		
	}else if (num_switch_pts == 1){

		num_samps = nrow(post_samples[[1]])

		ll_n = c()
		for(nn in 1:num_samps){
			ll_n = c(ll_n,	ll_BMswitch(Xn, post_samples[["tau"]][nn], post_samples[["theta"]][nn,], post_samples[["sigma_sq"]][nn,]) )	
		}
		return(	mean(ll_n))		
	}else{

		num_samps = nrow(post_samples[[1]])

		ll_n = c()
		for(nn in 1:num_samps){
			ll_n = c(ll_n,	ll_BMswitch(Xn, post_samples[["tau"]][nn,], post_samples[["theta"]][nn,], post_samples[["sigma_sq"]][nn,]) )	
		}
		return(	mean(ll_n))		
	}
	
}





