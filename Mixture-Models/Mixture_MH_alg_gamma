## Main Question
## It appears that the velocity of the tracked particles is coming from two distributions. We want to estimate the distribution of velocities using a mixture model

iterations = 5000
burn_index = 1:ceiling(0.1*iterations)

flag_sim = 1


var_alpha_1 = 1
var_alpha_2 = 1


##==================================================================
## Simulating the Data
##=================================================================
flag_sim = 1

if(flag_sim == 1){
par(mfrow = c(1,3), mar = c(5,4,1,1))


theta = 0.7 		#Probability of the motor being in the processive state
num_steps = 500  #Number of motor proteins we observed

true_state = rbinom(n = num_steps, size = 1, prob = theta)
state_0_ind = which(true_state == 0)
state_1_ind = which(true_state == 1)
#0 is immobilized state
#1 is processing state

#Parameters distriubtion of immobilized state
alpha_nu_0 = 2; beta_nu_0 = 20;  mean_nu_0 = alpha_nu_0/beta_nu_0

#Parameters of distrubtion of processing state
alpha_nu_1 = 5; beta_nu_1 = 5; mean_nu_1 = alpha_nu_1/beta_nu_1


#Generating the fake velocity data according to the mixture model
nu_vec = mat.or.vec(nc = 1, nr =num_steps)
nu_vec[state_0_ind] = rgamma(n = length(state_0_ind),shape = alpha_nu_0, rate = beta_nu_0 ) 
nu_vec[state_1_ind] = rgamma(n = length(state_1_ind),shape = alpha_nu_1, rate = beta_nu_1 ) 




print(paste("nu0 ~ Gamma(", alpha_nu_0, ",", beta_nu_0,")"))
print(paste("nu1 ~ Gamma(", alpha_nu_1, ",", beta_nu_1,")"))


##Plotting the mixture model and the fake data
nu_seq = seq(0.001, 2, by  = 0.01)
true_dist_pdf = function(x){(1-theta)*dgamma(x, shape = alpha_nu_0, rate = beta_nu_0) + theta*dgamma(x, shape = alpha_nu_1, rate = beta_nu_1)}
plot(nu_seq, true_dist_pdf(nu_seq), type = "l", ylab = "Density", main = "Mixture Model", xlab = expression( nu))
plot(true_state, pch = 16, main = "Simulated States")


##Saving the DATA!!
velocity_data = nu_vec


}



##=============================================================
## Random Walk Transistion function
##=============================================================
cand_RW = function(current, variance){
	return(rnorm(n=1, mean= current, sd = sqrt(variance)))
}



##=============================================================
## Initializing
##=============================================================

#-----------------------------------------------------------------------
## State Vector
#-----------------------------------------------------------------------

state_thresh = 0.5
state_0_index = which(velocity_data < state_thresh)
state_1_index = which(velocity_data >= state_thresh)
state_vec_i = rep(0, length(velocity_data))
state_vec_i[state_1_index ] = 1

plot(state_0_ind, velocity_data[state_0_ind], pch = 16, ylab = expression(nu), main = "True values", ylim = range(velocity_data), xlim = range(1:length(velocity_data)), xlab = "Index", cex = 0.8)
points(state_1_ind, velocity_data[state_1_ind], pch = 17, cex =0.8)
points(state_0_index, velocity_data[state_0_index], col = "firebrick3", pch = 0)
points(state_1_index, velocity_data[state_1_index], col = "springgreen3", pch = 0)


nu_0 = velocity_data[state_0_index]; nu_1 = velocity_data[state_1_index]
#-----------------------------------------------------------------------
## Miture probability p 
#-----------------------------------------------------------------------

p0_i = length(state_0_index)/(length(velocity_data))
p_vec_0 = c(p0_i, 1- p0_i)

#-----------------------------------------------------------------------
## Hyper Prior for rate parameters beta 
## Gibbs Sampling, gamma in conjugate prior
#-----------------------------------------------------------------------

#Method of moments estiamtes for betas 
beta_i_vec  = c(mean(velocity_data[state_0_index])/(var(velocity_data[state_0_index]))  ,mean(velocity_data[state_1_index])/(var(velocity_data[state_1_index])))


hyper_beta = rbind(c(beta_i_vec[1]/10, 1/10), c(beta_i_vec[2]*10, 10))
rownames(hyper_beta) = paste("nu", 1:2)
colnames(hyper_beta) = c("a","b")
## We want the hyper prior for the rate parameter to have mean equal to that of our method of moments and have a wide enough variance so we divide by a constant





#-----------------------------------------------------------------------
## Hyperprior for shape parameters alphas
#----------------------------------------------------------------------

##Method of moments estimate for alphas
alpha_i_vec = c(mean(velocity_data[state_0_index])^2/(var(velocity_data[state_0_index])),  mean(velocity_data[state_1_index])^2/(var(velocity_data[state_1_index])))  


hyper_alpha = rbind(c(4,40,2), c(2,3,2 )) 

rownames(hyper_alpha) = paste("nu", 1:2)
colnames(hyper_alpha) = c("a","b", "c")

alpha_post_log_density = function(x, a, b,c, beta){
	(x-1)*log(a) + x*c*log(beta) - b*log(gamma(x))
	}


##=============================================================
## Output
##=============================================================
p_n = matrix( nrow  = iterations, ncol = 2); p_n[1,] = p_vec_0
beta_n = matrix( nrow  = iterations, ncol = 2); beta_n[1,] = beta_i_vec
alpha_n = matrix(nrow = iterations, ncol = 2); alpha_n[1,] = alpha_i_vec
state_vec_n = matrix(nrow = iterations, ncol  = length(velocity_data))
state_vec_n[1,] = state_vec_i

accept_vec = matrix(nrow = iterations, ncol = 2)

colnames(p_n) = paste("p", 1:2);colnames(beta_n) = c(expression(beta[1]), expression(beta[2]));colnames(alpha_n) =  c(expression(alpha[1]), expression(alpha[2]))


for( i in 2:iterations){


##=============================================================
## Simulating the State
##=============================================================
den_0  = dgamma(velocity_data, shape = alpha_i_vec[1], rate = beta_i_vec[1])
den_1  = dgamma(velocity_data, shape = alpha_i_vec[2], rate = beta_i_vec[2])

prop_constant = den_0*p0_i + den_1*(1- p0_i)

pj_0 = p0_i*den_0/prop_constant

u_rv = runif(n = length(velocity_data), min = 0, max = 1)
state_0_index = which(pj_0 - u_rv >= 0)
state_1_index = which(pj_0 - u_rv < 0)

state_vec_i[state_0_index] = 0
state_vec_i[state_1_index] = 1

state_vec_n[i, ] = state_vec_i



##=============================================================
## Mixture Probability: Gibbs Sampling 
##=============================================================
n_0 = length(which(state_vec_i == 0))
n_1 =  length(which(state_vec_i == 1))

p_vec_i = rdirichlet(1, p_vec_0 + c(n_0, n_1))

p_n[i, ] =p_vec_i


##=============================================================
## Betas: Gibbs Sampling
##=============================================================

#For state 0
a0_post = hyper_beta[1,1] + n_0*alpha_i_vec[1]; b0_post = hyper_beta[1,2] + sum(velocity_data[state_0_index])
beta_i_vec[1] = rgamma(n =1, shape = a0_post, rate = b0_post )


#For state 1
a1_post = hyper_beta[2,1] + n_1*alpha_i_vec[2]; b1_post = hyper_beta[2,2] + sum(velocity_data[state_1_index])
beta_i_vec[2] = rgamma(n =1, shape = a1_post, rate = b1_post )


beta_n[i,] = beta_i_vec

##=============================================================
## Alphas: Conjugate Priors plus MHs
##=============================================================
beta1_i = beta_i_vec[1]

##State 0 
post_a = hyper_alpha[1,1]*prod(velocity_data[state_0_index]); post_b = hyper_alpha[1,2] + length(state_0_index); post_c = hyper_alpha[1,3] + length(state_0_index)


##MH Step to sample alpha 1 from posterior
alpha_1_cand = cand_RW(alpha_i_vec[1], var_alpha_1)

if(alpha_1_cand < 0){
	accept_vec[i,1] = 0
}else{
	post_ratio = alpha_post_log_density(alpha_1_cand, post_a, post_b, post_c, beta1_i) - alpha_post_log_density(alpha_i_vec[1], post_a, post_b, post_c, beta1_i)
	
	accept_fnc = exp(post_ratio)
	
	if(post_ratio >1){
		alpha_i_vec[1] = alpha_1_cand
		accept_vec[i,1] = 1	
	}else{
		if(runif(n = 1, min = 0, max = 1) <= accept_fnc ){
			alpha_i_vec[1] = alpha_1_cand
			accept_vec[i,1] = 1	
		}else{
			accept_vec[i,1] = 0			
			}
	}
	
	} #End of the MH loop to sample


##--------------------------------------------------
##State 2
##--------------------------------------------------

beta2_i = beta_i_vec[2]
post_a = hyper_alpha[2,1]*prod(velocity_data[state_1_index]); post_b = hyper_alpha[2,2] + length(state_1_index); post_c = hyper_alpha[2,3] + length(state_1_index)


##MH Step to sample alpha 2 from posterior
alpha_2_cand = cand_RW(alpha_i_vec[2], var_alpha_2)

if(alpha_2_cand < 0){
	accept_vec[i,2] = 0
}else{
	post_ratio = alpha_post_log_density(alpha_2_cand, post_a, post_b, post_c, beta2_i) - alpha_post_log_density(alpha_i_vec[2], post_a, post_b, post_c, beta2_i)
	
	accept_fnc = exp(post_ratio)
	
	if(post_ratio >1){
		alpha_i_vec[2] = alpha_2_cand
		accept_vec[i,2] = 1	
	}else{
		if(runif(n = 1, min = 0, max = 1) <= accept_fnc ){
			alpha_i_vec[2] = alpha_2_cand
			accept_vec[i,2] = 1	
		}else{
			accept_vec[i,2] = 0			
			}
	}
	
	} #End of the MH loop to sample


alpha_n[i,] = alpha_i_vec


}## End of Iterations loop



##=============================================================
##PLOTTING
##=============================================================


mean_p = apply(p_n[-burn_index,], 2, mean)

mean_alphas = apply(alpha_n[-burn_index,],2, mean )
sd_alphas = apply(alpha_n[-burn_index, ], 2, sd)
mean_betas = apply(beta_n[-burn_index,],2, mean )
sd_betas = apply(beta_n[-burn_index,], 2,sd) 

yalpha_0 = mean_alphas[1] + 3*sd_alphas[1]*c(-1,1);yalpha_1 = mean_alphas[2] + 3*sd_alphas[2]*c(-1,1)

ybeta_0 = mean_betas[1] + 3*sd_betas[1]*c(-1,1);ybeta_1 = mean_betas[2] + 3*sd_betas[2]*c(-1,1)

par(mfrow = c(1,2))
plot(state_vec_n[iterations,], pch = 16); points(true_state, col = "springgreen3", main = "State Vector")
plot(p_n[-burn_index,1], type = "l", main = "p", ylab = "p", xlab = "iterations", ylim = c(0,1))

par(mfrow = c(2,2), mar = c(5,4,1,1))
plot(alpha_n[-burn_index,1], main = expression(alpha[0]), type = "l",xlab = "iterations", ylab =expression(alpha[0]), ylim = yalpha_0)
abline(h = alpha_nu_0, col = "red")
plot(beta_n[-burn_index,1], main = expression(beta[0]),type = "l",xlab = "iterations", ylab =expression(beta[0]), ylim = ybeta_0)
abline(h = beta_nu_0, col = "red")


plot(alpha_n[-burn_index,2], main = expression(alpha[1]),type = "l",xlab = "iterations", ylab =expression(alpha[1]), ylim = yalpha_1)
abline(h = alpha_nu_1, col = "red")

plot(beta_n[-burn_index,2], main = expression(beta[1]),type = "l",xlab = "iterations", ylab =expression(beta[1]),ylim = ybeta_1 )
abline(h = beta_nu_1, col = "red")





nu_seq = seq(0.001, 2, by  = 0.01)
par(mfrow = c(1,1))



true_dist = (1-theta)*dgamma(nu_seq, shape = alpha_nu_0, rate = beta_nu_0) + theta*dgamma(nu_seq, shape = alpha_nu_1, rate = beta_nu_1)


predicted_density = function(vel_vec , mix_p, par_1, par_2){
	return(mix_p*dgamma(vel_vec, shape = par_1[1], rate = par_1[2]) + (1-mix_p)*dgamma(vel_vec, shape = par_2[1], rate = par_2[2]))
	
}


plot(nu_seq, true_dist, type = "l", ylab = "Density", main = "Mixture Model", xlab = expression( nu), ylim = range(true_dist))

sample_par_index = seq(ceiling(iterations*0.5),iterations, length = 11)

for(kk in sample_par_index){

lines(nu_seq, predicted_density(nu_seq, p_n[kk],c(alpha_n[kk,1], beta_n[kk,1]), c(alpha_n[kk,2], beta_n[kk,2]) ), type = "l", ylab = "Density", col = "dodgerblue3")

}
lines(nu_seq, true_dist, type = "l", lwd = 2)

legend( "topright"  ,legend = c("Simulated", "Posteriod Predicted"), lty = 1, col = c("black", " dodgerblue3"))



print(paste("Posterior nu0 ~ (", round(mean_alphas[1],2), round(mean_betas[1], 2), ")"))
print(paste("Posterior nu1 ~ (", round(mean_alphas[2],2), round(mean_betas[2], 2), ")"))




##=================================
##INFERENCE ON MODEL SELECTION
##================================
true_dist_cdf = function(x){(1-theta)*pgamma(x, shape = alpha_nu_0, rate = beta_nu_0) + theta*pgamma(x, shape = alpha_nu_1, rate = beta_nu_1)}

conv_ind = max(burn_index)+1

mixture_nus = c(); simple_nus = c()

for(i in conv_ind:iterations){

my_p0 =  p_n[i, ]  #rdirichlet(1,mean_p + c(n_0, n_1))

my_betas = beta_n[i,]
my_alphas = alpha_n[i, ]


##Simulating nu from Posterior distributions
num_pts = 1#length(fake_data)
sim_states = rbinom(1,size =1 , prob = my_p0[2] )
my_nu = rgamma(n = 1, shape =  my_alphas[sim_states + 1], rate = my_betas[sim_states+1])


mixture_nus = c(mixture_nus, my_nu)


} #End of Iteration loop


 par(mfrow = c(1,2), mar = c(5,4,1,1))

ecdf_data = ecdf(velocity_data)
ecdf_mixture = ecdf(mixture_nus)

xx = seq(0.001, 2.5, by = 0.01)

plot(ecdf(velocity_data), main = "Emperical  CDF", xlab = expression(nu))
lines(xx,ecdf_mixture(xx), col = "springgreen3", lwd = 2)
lines(xx, true_dist_cdf(xx), col = "slateblue3", lwd = 2)

p_const = (1/diff(xx)[1])

plot(xx[-1], diff(ecdf_data(xx))*p_const, col = "black", type = "l", main = "Density", xlab = expression(nu), ylab = "Density", lty = 2)
lines(xx[-1], diff(ecdf_mixture(xx))*p_const, col = "springgreen3", type = "l", lwd = 2)
lines(xx[-1], diff(true_dist_cdf(xx))*p_const, col = "slateblue3", lwd = 2)



legend("top", legend = c("Data", "Mixture: Post Predictive", "True Mixture Distribution"), col = c("black", "springgreen3", "slateblue3"), lwd = c(1,2,2,2), cex  = 1)

title("Mixture Model", outer = TRUE)


# 



# # 
# par(mfrow = c(1,2), mar = c(5,4,1,1), oma = c(0,0,2,0))

# k = 1


# xx = seq(0.001, 4, by = 0.01)
# plot(xx, alpha_post_log_density(xx, a = hyper_alpha[k,1], b = hyper_alpha[k,2], c = hyper_alpha[k,3], beta_i_vec[1]), type = "l", ylab = "Density",xlab = expression(alpha[0]));
# abline(v = alpha_i_vec[1], col = "red")
# title(paste("True alpha = ", alpha_nu_0))



 # k = 2
# xx = seq(3, 14, by = 0.01)
# plot(xx, alpha_post_log_density(xx, a = hyper_alpha[k,1], b = hyper_alpha[k,2], c = hyper_alpha[k,3], beta_i_vec[2]), type = "l", ylab = "Density", xlab = expression(alpha[1]));
 # abline(v = alpha_i_vec[2], col = "red")

# points(alpha_i_vec[k],hx(alpha_i_vec[k], a = hyper_alpha[k,1], b = hyper_alpha[k,2], c = hyper_alpha[k,3], beta_i_vec[k]), pch = 8 )
# title(paste("True alpha = ", alpha_nu_1))


# title("Priors on Shape Parameter ", outer = TRUE)





